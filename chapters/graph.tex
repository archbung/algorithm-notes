\section{Graph}
Graph $G=(V,E)$ is defined with a set of vertices $V$ and set of edges $E$.
Now, some notations:
\begin{description}
  \item[Sizes] $m=|E|$ and $n=|V|$
  \item[Directed edge] $[u,v\rangle=\langle v,u]$ denotes an edge from $u$ to
    $v$
  \item[Out- and In- degree] number of edges going out and in of vertex $v$,
    $Out(v)$ and $In(v)$ respectively
  \item[Path] if there's a path from $u$ to $v$ then we write
    $u\rightsquigarrow v$
  \item[Topological Sort] vertices of a directed acyclic graph (dag) can be
    numbered such that each edge leads from a smaller to a larger number
\end{description}

There are two ways to represent graphs: adjacency matrices and adjacency lists.
Adjacency matrix needs space $O(n^2)$, which is inefficient for sparse graphs.
Conversely, adjacency list needs space $$\sum_{v\in V} (Out(v) + 1)=|E|+n=m+n$$
which is efficient for sparse graphs.


\subsection{Searching}
Depth-First Search (DFS) creates a search tree by exploring each node until it
reach some node that doesn't have any outgoing nodes or the only outgoing nodes
are already visited.  A DFS pseudocode is shown in Algorithm~\ref{graph:dfs}.
Since DFS visits each vertex $u$ exactly once and at each visit it explores
every vertices $v\in Out(u)$, the running time is:
$$O(\sum_{v\in V}(Out(v)+1))=O(m+n)$$

\begin{algorithm}
  \caption{Depth-First Search}\label{graph:dfs}
  \begin{algorithmic}
    \Function{DFS}{g}
    \ForAll{v in V}\Comment{Initialization}
      \State $color[v]=\texttt{white}$
      \State $\pi[v]=\texttt{nil}$\Comment{Parent pointer}
    \EndFor
    \State $time = 0$
    \ForAll{v in V}
      \If{$color[v]=\texttt{white}$}
        \State\Call{DFS-visit}{v}
      \EndIf
    \EndFor
    \EndFunction
    \State
    \Function{DFS-visit}{u}
      \State $color[u]=\texttt{grey}$
      \State $d[u]=t+1$\Comment{Discovery time}
      \ForAll{v in Out[u]}
      \If{$color[v]=\texttt{white}$}
        \State\Call{DFS-visit}{v}
        \State $\pi[v]=u$
      \EndIf
      \State $color[u]=\texttt{black}$
      \State $f[u]=time+1$\Comment{Finishing time}
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{lemma}
  If $u\rightsquigarrow v$ but not $v\rightsquigarrow u$, then after a DFS we have $f[u]>f[v]$
\end{lemma}
\begin{proof}
  We proceed by case distinction.  If $u$ is visited first, then DFS will
  finish exploring $v$ before $u$.  Otherwise $v$ is visited first, but since
  there's no path from $v$ to $u$, DFS will finish exploring $v$ before $u$.
  In both cases, $f[u]>f[v]$
\end{proof}

\begin{definition}{Strongly connected component.}
  Vertices $u$ and $v$ are cycle equivalent iff $u=v$ or $u\rightsquigarrow v$
  and $v\rightsquigarrow u$.  This equivalence class are the strongly connected
  components.
\end{definition}

DFS can be used to compute strongly connected components in graph $G$.  The
goal is to number the vertices in such a way so that if a DFS is done using
this numbering as the guide of which vertex to visit first, then the strongly
connected components are discovered as the trees of the DFS forest.  It turns
out that it suffices for this numbering to be such that if $u\rightsquigarrow
v$ but not $v\rightsquigarrow u$, then $\texttt{number}(u)>\texttt{number}(u)$.
The algorithm that computes strongly connected component this way is proceed as
follows:
\begin{enumerate}
  \item Call $\texttt{DFS}(G)$ to compute the finishing time $f[u]$ for all
    $u\in V$.
  \item Compute $G^T$ which is $G$ with all its edges reversed.
  \item Call $\texttt{DFS}(G^T)$, but consider vertices by decreasing finishing
    time.
  \item Output the vertex set of the trees of the resulting DFS forest as the
    strongly connected components.
\end{enumerate}

\begin{theorem}
  Strongly connected components can be computed in $O(m+n)$ time.
\end{theorem}
\begin{proof}
  Since computing $G^T$ takes $O(m)$ time, the running time of this algorithm
  follows from the running time of DFS.
\end{proof}


\subsection{Single Source Shortest Path}
Given a directed graph $G$, assign weight/cost $w: E\rightarrow\mathbb{R}$ to
each edge.  This can be generalized easily to undirected graphs by creating two
edges (one for each direction) for every edges in the directed graph, and then
assigning weight appropriately.
\begin{definition}{Shortest path}
  A path $p=\langle u_0,\ldots,u_k\rangle$ from
  $u=u_0\xrightarrow{e_1}\ldots\xrightarrow{e_k} u_k=v$ has a total weight of
  $w(p)=\sum_i w(e_i)$.  Shortest path is path with minimal weight.
\end{definition}

Therefore the single source shortest path (SSSP) problem can be stated as given
a starting vertex $s$, compute the shortest $s$-$v$ path $d[v]$ for all $v\in
V$.

\begin{theorem}{Subpath optimality.}
  \label{graph:subpath-optimality}
  If $d[u]=w(p)$, $p=\langle s=u_0,\ldots,u_k=u\rangle$ is a shortest $s$-$v$
  path, then for every $u_i$, $0\leq i<k$, $d[u_i]$ is also a shortest path.
\end{theorem}
\begin{proof}
  We proceed by contraposition.  Suppose $d[u_i]$, for some $i$, is not
  a shortest path.  Then there is a shortest path $d'[u_i]\leq d[u_i]$.  But
  then, using $d'[u_i]$, we can construct a path $d'[u]\leq d[u]$.
\end{proof}

\begin{algorithm}
  \caption{Relaxing edge $e=[u,v\rangle$}\label{graph:edge-relax}
  \begin{algorithmic}
    \Function{relax}{e}
      \If{$\delta[u]+w([u,v\rangle)<\delta[v]$}\Comment{$\delta$ is the current shortest path}
      \State $\delta[v]=\delta[u]+w([u,v\rangle)$
      \State $\pi[v]=u$
      \EndIf
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{definition}{Negative cycle.}
  A negative cycle is a cycle with negative overall weight.
\end{definition}

\begin{lemma}
  \label{graph:relax}
  Assuming no negative cycles, a shortest path
  $s=u_0\xrightarrow{e_1}\ldots\xrightarrow{e_k}u_k$ if a sequence of relax
  operations happen that contains
  $\texttt{relax}(e_1),\ldots,\texttt{relax}(e_k)$ as a subsequence (not
  necessarily contiguous), then afterwards we have $\delta[u_k]=d[u_k]$.
\end{lemma}

The simplest algorithm to compute SSSP is the Bellman-Ford algorithm, shown in
Algorithm~\ref{graph:bellman-ford}.  The correctness of this algorithm follows
from Lemma~\ref{graph:relax}.  It is straightforward to show that the
Bellman-Ford algorithm runs in $O(nm)$ time.
\begin{algorithm}
  \caption{Bellman-Ford}\label{graph:bellman-ford}
  \begin{algorithmic}
    \Function{Bellman-Ford}{G}
      \State Initialize $d[v]$ and $\pi[v]$ for all $v\in V$
      \For{$i=1$ to $n-1$}
        \ForAll{edge $e$ in path}
        \State \texttt{relax}(e)
        \EndFor
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{algorithm}

If all edge weights are non-negative, we can use Dijkstra's algorithm
(Algorithm~\ref{graph:dijkstra}).  To implement Dijkstra's algorithm
efficiently, we need a priority queue \texttt{PQ} which can be implemented
using a Fibonacci heap or a hollow heap.  Since \texttt{delteMin} takes $O(\log
n)$ and $\sum_v Out(v)=m$, Dijkstra's algorithm runs in $O(n\log n+m)$.
\begin{algorithm}
  \caption{Dijkstra}\label{graph:dijkstra}
  \begin{algorithmic}
    \Function{Dijkstra}{G}
    \State Creates \texttt{PQ} with $v$ for all $v\in V$
    \State Initializes the key with initial $\delta[v]$
      \While{$\texttt{PQ}\ne\emptyset$}
        \State $u=\texttt{delteMin}(\texttt{PQ})$\Comment{Now $\delta[u]=d[u]$}
        \ForAll{$v\in Out(u)$}
          \If{$\delta[u]+w([u,v\rangle)<\delta[v]$}
            \State $\delta[u]+w([u,v\rangle)=\delta[v]$
            \State $\pi[v]=u$
            \State $\texttt{decreaseKey}(v)$
          \EndIf
        \EndFor
      \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

To argue for correctness of Dijkstra's algorithm, we use the following
invariants.  Define $U$ as the set of vertices not in \texttt{PQ} anymore and
$U'=V\setminus U$.  Then for all $u\in U$, $\delta[u]=d[u]$ and $\pi[u]$ gives
the shortest path tree.  On the other hand, for all $v\in U'$,
$\delta[v]\geq\max\{\delta[u]|u\in U\}$.


\subsection{All Pairs Shortest Path}
The All Pairs Shortest Path (APSP) problem asks to compute the shortest
$i\rightsquigarrow j$ for all $(i,j)\in V^2$.  Related to this problem is the
All Pairs Distance problem, which asks the length of the shortest path for all
pairs of vertices.  Given a graph $G=(V,E)$, the trivial solution is to run the
Bellman-Ford algorithm for each $v\in V$.  This gives us a running time of
$O(n^2m)$.  Can we do better?

\begin{definition}{Reduced costs.}
  Define a function $\phi: V\rightarrow\mathbb{R}$.  Then the reduced cost is
  $w_\phi([u,v\rangle)=w(u,v\rangle)+\phi(u)-\phi(v)$.
\end{definition}
Given a path $p=u_0\xrightarrow{e_1}\ldots\xrightarrow{e_k}u_k$, the reduced cost
of this path is,
\begin{align*}
  w_\phi(p) &= w_\phi(u_0\xrightarrow{e_1}\ldots\xrightarrow{e_k}u_k)\\
            &= (\phi(u_0)+w(e_1)-\phi(u_1))+\ldots+(\phi(u_k-1)+w(e_k)-\phi(u_k))\\
            &= \phi(u_0)+w(e_1)+\ldots+w(e_k)-\phi(u_k)\\
            &= \phi(u_0)+w(p)-\phi(u_k)\\
\end{align*}
therefore shortest path with respect to $w$ is also shortest path with respetc
to $w_\phi$.

Now we proceed to outline a faster algorithm for APSP.  The idea is to use
Dijkstra's algorithm somehow (recall that it requires all the costs to be
non-negative, so it can't be applied directly to arbitrary graphs).  To do
this, we proceed as follows:
\begin{enumerate}
  \item Pick some $s\in V$
  \item Run Bellman-Ford to solve SSSP for $s$, we get $d[v]$ for all $v\in V$
  \item Choose $\phi=\max\{d[v]|v\in V\}$
  \item Run Dijkstra's algorithm with reduced costs $w_\phi$
\end{enumerate}
It is straightforward to show that this algorithm runs in $O(n^2\log n + nm)$
time.  This algorithm works since after running Bellman-Ford algorithm, no edge
can be relaxed anymore.  Therefore we have $d[v]\leq d[u]+w([u,v\rangle)\iff
  0\leq d[u]+w[u,v\rangle -d[v]$ and thus $w_\phi\geq 0$.


\subsection{Minimum Spanning Tree}
Consider an undirected graph $G=(V,E)$ with weights $w$ associated to each of
its edges.  The Minimum Spanning Tree (MST) of this graph is a tree that spans
the entire vertices of $G$ and has minimum total weight. 

\begin{definition}{Cut edge.}
  Partition the vertices $V$ of a graph $G$ into nonempty set $U$ and $U'$.  An
  edge $e=[i,j]$ is a cut edge if $i\in U$ and $j\in U'$.
\end{definition}
\begin{lemma}
  If $U$ and $U'$ is a cut of $G$ and $e$ is a cut edge of minimal weight, then
  there exists an MST for $G$ that contains $e$.
\end{lemma}
\begin{proof}
  Suppose there's a spanning tree $T$ that doesn't include $e$.  Then it must
  include some other cut edge $e'$ that connects $U$ and $U'$, otherwise it
  wouldn't be a spanning tree.  By using $e$ instead of $e'$, $T$ will have
  minimal weight, hence becoming an MST.
\end{proof}
\begin{lemma}
  Let $C$ be a cycle in $G$ and let $e$ be an edge of $C$ that has larger
  weight than any other edges of C.  Then no MST of $G$ contains $e$.
\end{lemma}
\begin{proof}
  Choose $U$ and $U'$ such that $e$ be one of the cut edges.  Since $C$ is
  a cycle, there exists another cut edges $e'$ with $w(e')<w(e)$.
  A spanning tree of $G$ will have a lower weight if it includes $e'$ instead
  of $e$, therefore a spanning tree which includes $e$ cannot be an MST.
\end{proof}


% This is the start of the flow algorithms
%\subsection{Flow Problem}
%Given a directed graph $G=(V, E)$, we can construct a flow network by defining
%a capacity function $u: E\rightarrow R$ and a flow function $f: E\rightarrow
%R$, with relation as follows.

%Residual graph
%It must be possible to undo the flow

%\subsubsection{Ford Fulkerson}
%In residual graph, find augmenting path until t is not reachable from
%s i.e. there's an edge with residual flow equal 0

%\subsubsection{Edmunds-Karp Algorithm}
%As augmenting path, always choose an s-t path with smallest number of edges,
%which can be found via BFS in $O(m + n)$ time.

%with BFS, we can't have down edges (if you put s at top and t somewhere below it) that jumps a level

%augmentation along shortest path:
%- saturate at least one down edge effectively kills it in the residual graph
%- creates only up edges
%Note that this cannot shorten any s-t path

%Observation: can do saturation at most m times
%=> after <= m iterations distance between s and t must increase
%Distance can increase <n times
%This means total number of augmentations is less than $mn$
%Since finding an augmenting path takes linear time, then total running time is $O(m^2n)$

%\subsubsection{Blocking flows algorithm}
%Level network (BFS on graph)
%f is blocking flow in level network if $G_f$ admits no downward s-t path

%repeat
	%form level graph in $G_f$ (BFS starting from s)
	%find a blocking flow $f'$ in $G_f$
	%$f = f + f'$
%until s and t are not connected in $G_f$

%Note that like EK alg above, each iteration increases distance between s and
%t in $G_f$, so there are at most <n iterations.

%Now how to find blocking flow?
%DFS to find s-t path
	%assume no backtrack -> augment this path, then saturates one edge

	%if you backtrack along an edge (t cannot be reached along this edge)
		%you can remove this edge from consideration

%throughput(v) = min{capacity out, capacity in}

%Consider case where all edges have capacity 1.  Then finding a blocking flow takes O(m) time


%\subsubsection{Unit Network}
%All edges have capacity 1.
%For all nodes v in V\\{s,t}, either indeg(v) = 1 or outdeg(v) = 1

%Observation: any residual graph of a unit network is also a unit network.  
%Why?  Take any node and see that the resulting residual graph is basically the
%flow network but with the edges reversed.

%Claim: Given unit network, and shortest path from s to t has $k+1$ edges.  This
%implies the max flow can have value at most $n/_k$
%Proof: Need to show s-t cut with capacity at most $n/_k$
%Make a level graph.  Then there's a level with at most $n/_k$ vertices.  Then
%take any vertices with one node coming in as the t part and any vertices with
%one node coming out as the s part, forming a cut.  Since this level has at most
%$n/_k$ vertices, then the cut has $n/_k$ edges coming in and out.  Since every
%edge has capacity 1, then $n/_k$ is the capacity of the cut, which is also the
%max flow.

%Algorithm for unit network (Karp, Hopcroft)
%1. Run $\sqrt n$ iterations of blocking flow
%2. Run $\sqrt n$ augmenting path finding


%\subsection{Circulation Problem}
%Network with edge capacities c: E -> Real but no source and sink nodes
%But we have supply/demand b: B -> Real (positive for supply, negative for
%demand)

%Constraint: b(V) = 0, that is, sum of all supply at all vertices is zero

%Want: flow func f: E -> positive Real such that for every vertices v,
	%Inflow(v) - Outflow(v) + b(v) = 0

%Solutions need not exists!
%Therefore the question really is, is the problem feasible?  That is, is there
%such f?

%It turns out we can solve this using the max flow
%Lemma: for every circulation problem in G= (V, E; c, b), there exists a max flow
%problem G'= (V', E'; c') s, t such that circulation problem is feasible iff max
%flow value for G' is the sum of all supplies.


%\subsubsection{Min Cost Circulation Problem}
%Cycle cancelling
%1. Start with a feasible circulation e.g. $\forall a f(a) = 0$
%2. While there's a negative directed circuit $Z\subseteq A^f$ in $G^f$
   %a. compute $\tau = \min \{u^f(a) \in Z\}$
   %b. update every edge $a$: $f(a) = f(a) + \tau if a \in Z f(a) - \tau if -a \in Z f(a) otherwise$
   %c. return f

%Theorem: A feasible circulation $f: A -> Z$ is of minimum cost iff
%$G^f$ does not contain a negative directed circuit.
%Proof:
%1. Necessity: suppose there's a negative directed circuit. Thus we
%could update and get a bigger flow, and thus even smaller cost.
%2. Sufficiency: Suppose that each directed circuit in $G^f$ has non-negative cost.  Now we can show that f is indeed the min cost

%Theorem: Choosing a Minimum Mean Cycle (MMC) in each iteration leads to at most $4nm^2\ceil \ln n$
%Proof:
%Let $f, f^{-1},\ldots$ be the circulation found in.  For each 

%\subsubsection{Reduction to regular circulation problem}
%do some weird shit

%% This is the end of the flow algorithms


%\subsection{Matching}
%$G=(V,E)$ undirected graph
%Match $M\in E$ such that every vertices incident to at most 1 edge in M

%M is called maximal iff there's no matching M' with M strictly inside M.  In
%other words, can't add more edges to M.

%M is called maximum if |M| is as large as possible.

%\subsubsection{Matching in Bipartite Graph}
%G is bipartite if we can partition V into A and B and all edges are between
%vertices in A and vertices in B.

%How to find the maximum matching?  Use the unit network algorithm in time
%O(m\sqrt n)

%\subsubsection{Matching in General Graph}
%Alternating path in a graph with matching M is a path whose edges alternate
%between in M and not in M.

%Augmenting alternating path if it starts and ends in two distinct unmatched
%vertices.

%Augmenting path lemma:
%Graph $G=(V,E)$ and matching $M\in E$.  M is maximum iff there's no augmenting
%alternating path.
%Proof: 
%- if there's an augmenting alternating path then we can always construct a bigger matching.
%- assume M is not maximum and M* be the maximum matching.
	%1 could be a cycle (same number of edge for M and M*)
	%2 could be a path
	%3 could be that M and M* contain the same edges
  %since M* is bigger, then there must be situation 2, where we get the augmenting alternating path.

%Notion of stem, root, and blossom (which always with respect to some matching M)
%Blossom is basically an odd cycle attached to root.
%Stem always starts with a free vertex and has even edges.

%Shrinking a blossom -> contract blossom to a single vertex.

%Theorem:
%Graph $G=(V,E)$, matching M and B blossom with respect to M.  There exists an
%augmenting alternating path in G iff there exists an augmenting alternating
%path in G with B shrinked.

%Alg to find an augmenting alternating path in O(mn)
%M matching
%free vertices
%matched vertices w, mate(w) -> M = {w,mate(w)}
%Find "alternating" forest
	%node are marked with "unlabelled" "odd" "even"
%Initially all free vertices are even and matched vertices are unlabelled.

%Pick some even node v and let w some adjacent vertex
%Explore edge {v,w}.  Now there are several cases
%1. w is unlabelled -> make w child of v; make mate(w) child of w; label w as odd; label mate(w) as even
%2. w is odd -> do nothing
%3. w is even -> if in different tree then found an alternating path
		%else found a blossom; shrink it and start anew

%Therefore we can find a matching in $O(n^2m)$

